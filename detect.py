# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Run inference on images, videos, directories, streams, etc.

Usage - sources:
    $ python path/to/detect.py --weights yolov5s.pt --source 0              # webcam
                                                             img.jpg        # image
                                                             vid.mp4        # video
                                                             path/          # directory
                                                             path/*.jpg     # glob
                                                             'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python path/to/detect.py --weights yolov5s.pt                 # PyTorch
                                         yolov5s.torchscript        # TorchScript
                                         yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                         yolov5s.xml                # OpenVINO
                                         yolov5s.engine             # TensorRT
                                         yolov5s.mlmodel            # CoreML (macOS-only)
                                         yolov5s_saved_model        # TensorFlow SavedModel
                                         yolov5s.pb                 # TensorFlow GraphDef
                                         yolov5s.tflite             # TensorFlow Lite
                                         yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
"""

import argparse
import os
import sys
from pathlib import Path

import torch
import torch.backends.cudnn as cudnn

FILE = Path(__file__).resolve() # å¾—åˆ°ç»å¯¹è·¯å¾„ C:\Users\zkh\Desktop\yolov5\detect.py
ROOT = FILE.parents[0]  # è·å¾—detect.pyçš„çˆ¶ç›®å½•  YOLOv5 root directory, C:\Users\zkh\Desktop\yolov5
if str(ROOT) not in sys.path: # æ¨¡å—çš„æŸ¥è¯¢è·¯å¾„çš„åˆ—è¡¨
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative ,ç»å¯¹è·¯å¾„è½¬æ¢æˆç›¸å¯¹è·¯å¾„

from models.common import DetectMultiBackend
from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams
from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import select_device, time_sync


@torch.no_grad()
def run(
        weights=ROOT / 'yolov5s.pt',  # model.pt path(s)  æ¨¡å‹æƒé‡
        source=ROOT / 'data/images',  # file/dir/URL/glob, 0 for webcam
        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path
        imgsz=(640, 640),  # inference size (height, width)
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save_conf=False,  # save confidences in --save-txt labels
        save_crop=False,  # save cropped prediction boxes
        nosave=False,  # do not save images/videos
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=False,  # update all models
        project=ROOT / 'runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        line_thickness=3,  # bounding box thickness (pixels)
        hide_labels=False,  # hide labels
        hide_conf=False,  # hide confidences
        half=False,  # use FP16 half-precision inference
        dnn=False,  # use OpenCV DNN for ONNX inference
):
    source = str(source) # 'python detect.py --source data\\images\\bus.jpg'
    save_img = not nosave and not source.endswith('.txt')  # save inference images  æ˜¯å¦ä¿å­˜æ¨ç†çš„å›¾åƒ ä¸º True 
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)   # suffixè¡¨ç¤ºåç¼€
    # ä½¿ç”¨Path(source).suffix[1:]è·å–sourceè·¯å¾„çš„åç¼€åï¼Œå¹¶å°†å…¶å»é™¤ç¬¬ä¸€ä¸ªå­—ç¬¦ï¼ˆé€šå¸¸æ˜¯.ï¼‰ã€‚
    # ç„¶åï¼Œæ£€æŸ¥è¯¥åç¼€åæ˜¯å¦åœ¨IMG_FORMATSå’ŒVID_FORMATSåˆ—è¡¨ä¸­ã€‚
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://')) # False
    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file) # False
    if is_url and is_file:
        source = check_file(source)  # download ä¸‹è½½å›¾ç‰‡æˆ–è€…è§†é¢‘
 


    # Directories æ–°å»ºä¸€ä¸ªä¿å­˜ç»“æœçš„æ–‡ä»¶å¤¹,projectå’Œnameå°±æ˜¯project=ROOT / 'runs/detect',å’Œ name='exp', 
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run, runs\\detect\\exp3
    # å°†projectå’Œnameæ‹¼æ¥æˆä¸€ä¸ªè·¯å¾„ã€‚Path(project)åˆ›å»ºä¸€ä¸ªPathå¯¹è±¡,è¡¨ç¤ºprojectçš„è·¯å¾„,ç„¶åä½¿ç”¨/è¿ç®—ç¬¦å°†å…¶ä¸nameæ‹¼æ¥ã€‚
 
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

    """
    save_dir æ˜¯ä¸€ä¸ªå˜é‡ï¼Œè¡¨ç¤ºå°†è¦ä¿å­˜æ–‡ä»¶çš„ç›®å½•ã€‚
    save_txt æ˜¯ä¸€ä¸ªå¸ƒå°”å˜é‡ï¼Œç”¨äºæŒ‡ç¤ºæ˜¯å¦ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ã€‚
    å¦‚æœ save_txt ä¸ºçœŸï¼Œåˆ™å°†åœ¨ save_dir ç›®å½•ä¸‹åˆ›å»ºåä¸º 'labels' çš„å­ç›®å½•ã€‚
    å¦‚æœ save_txt ä¸ºå‡ï¼Œåˆ™ç›´æ¥åœ¨ save_dir ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶å¤¹ã€‚
    mkdir() æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºç›®å½•ã€‚
    parents = True è¡¨ç¤ºå¦‚æœçˆ¶ç›®å½•ä¸å­˜åœ¨ï¼Œä¹Ÿä¼šä¸€å¹¶åˆ›å»ºçˆ¶ç›®å½•ã€‚
    exist_ok=True è¡¨ç¤ºå¦‚æœç›®å½•å·²ç»å­˜åœ¨ï¼Œä¸ä¼šå¼•å‘é”™è¯¯ï¼Œè€Œæ˜¯ç»§ç»­æ‰§è¡Œã€‚
    """



    # Load model
    device = select_device(device)

    # æ ¹æ®ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶è®°è½½æ¨¡å‹ï¼ˆpytorch tensorflow ï¼‰
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
    stride, names, pt = model.stride, model.names, model.pt  # stride = 32, ptæ˜¯pytorchçš„ç¼©å†™ï¼Œstrideç­‰äº321
    # print("pt",pt)  result:True
    # print("names",names)  æ‰“å°å‡ºæ‰€æœ‰çš„ç±»åˆ«åï¼Œä¸€å…±æœ‰80ä¸ªç±»åˆ«

    imgsz = check_img_size(imgsz, s=stride)  # check image å›¾åƒå°ºå¯¸sizeå¿…é¡»æ˜¯32çš„å€æ•°

    # Dataloader
    if webcam:
        view_img = check_imshow()  #æ£€æŸ¥èƒ½å¦æ˜¾ç¤ºå›¾ç‰‡

        # cudnn.benchmark æ ‡å¿—ç”¨äºå¯ç”¨ CUDNN åº“çš„è‡ªåŠ¨è°ƒä¼˜åŠŸèƒ½ã€‚
        # è¿™å…è®¸ CUDNN è‡ªåŠ¨è°ƒæ•´å…¶å†…éƒ¨ç®—æ³•,æ‰¾åˆ°æœ€å¿«çš„å·ç§¯ç®—æ³•,é€‚åˆæ‚¨çš„ç¡¬ä»¶ã€‚è¿™å¯ä»¥å¸¦æ¥æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœ,ç‰¹åˆ«æ˜¯å¯¹äºè¾“å…¥å¤§å°ä¿æŒä¸å˜çš„æ¨¡å‹ã€‚
        cudnn.benchmark = True  # set True to speed up constant image size inference
        """
        å°†cudnn.benchmarkè®¾ç½®ä¸ºTrueå¯ä»¥åŠ é€ŸPyTorchä¸­å¯¹å…·æœ‰æ’å®šè¾“å…¥å°ºå¯¸çš„æ¨¡å‹è¿›è¡Œæ¨æ–­çš„è¿‡ç¨‹ã€‚ä¸‹é¢æ˜¯å®ƒçš„ä½œç”¨å’Œå·¥ä½œåŸç†;

        CuDNN(CUDAæ·±åº¦ç¥ç»ç½‘ç»œåº“)æ˜¯ä¸€ç§é’ˆå¯¹æ·±åº¦å­¦ä¹ ä»»åŠ¡è¿›è¡Œä¼˜åŒ–çš„GPUåŠ é€Ÿåº“ã€‚
        åœ¨PyTorchä¸­,CuDNNä¸»è¦ç”¨äºæ‰§è¡Œå·ç§¯å’Œæ± åŒ–ç­‰æ“ä½œ,ä»¥åŠ é€Ÿç¥ç»ç½‘ç»œçš„è®­ç»ƒå’Œæ¨æ–­è¿‡ç¨‹ã€‚
        å½“cudnn.benchmarkè®¾ç½®ä¸ºTrueæ—¶,PyTorchä¼šåœ¨æ¯æ¬¡è¿›è¡Œå·ç§¯æ“ä½œæ—¶,æ ¹æ®å½“å‰çš„è¾“å…¥å°ºå¯¸å’Œå…¶ä»–ç›¸å…³å‚æ•°ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆå½“å‰ç¡¬ä»¶ç¯å¢ƒçš„å·ç§¯å®ç°ç­–ç•¥ã€‚
        è¿™ä¸ªé€‰æ‹©è¿‡ç¨‹ä¼šåœ¨ç¬¬ä¸€æ¬¡æ‰§è¡Œå·ç§¯æ“ä½œæ—¶è¿›è¡Œï¼Œå¹¶ä¸”ä¼šæ ¹æ®ç¡¬ä»¶ã€è¾“å…¥å°ºå¯¸å’Œå…¶ä»–æ¡ä»¶çš„å˜åŒ–è€Œé‡æ–°é€‰æ‹©ã€‚

        ï¼Œä»¥æ‰¾åˆ°æœ€ä¼˜çš„å·ç§¯ç®—æ³•ã€‚ç„¶åï¼Œå®ƒä¼šå°†è¿™äº›é€‰æ‹©ç¼“å­˜èµ·æ¥ï¼Œä»¥ä¾¿åœ¨åç»­çš„æ¨æ–­ä¸­é‡å¤ä½¿ç”¨ã€‚
        è¿™æ ·ä¸€æ¥ï¼Œå½“ä½¿ç”¨ç›¸åŒå°ºå¯¸çš„è¾“å…¥è¿›è¡Œæ¨æ–­æ—¶,PyTorchå°±å¯ä»¥ç›´æ¥ä½¿ç”¨ä¹‹å‰ç¼“å­˜çš„æœ€ä¼˜ç®—æ³•,ä»è€Œæé«˜æ¨æ–­é€Ÿåº¦ã€‚
        """
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)
        bs = len(dataset)  # batch_size
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)
        bs = 1  # batch_size
    vid_path, vid_writer = [None] * bs, [None] * bs

    # Run inference
    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup å¯¹æ¨¡å‹è¿›è¡Œé¢„çƒ­ï¼Œä¸ºåç»­çš„æ¨ç†åšå‡†å¤‡ã€‚
    dt, seen = [0.0, 0.0, 0.0], 0  # å¦‚æ—¶é—´è®°å½•å’Œå·²å¤„ç†æ•°æ®çš„è®¡æ•°ã€‚
    for path, im, im0s, vid_cap, s in dataset: # "C:\\Users\\zkh\\Desktop\\yolov5\\data\\images\\bus.jpg"
        t1 = time_sync()
        im = torch.from_numpy(im).to(device) # torch.Size([3, 640, 480])
        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
        im /= 255  # 0 - 255 to 0.0 - 1.0 å°†å›¾åƒçš„åƒç´ å€¼ä» 0 åˆ° 255 çš„èŒƒå›´å½’ä¸€åŒ–åˆ° 0.0 åˆ° 1.0 çš„èŒƒå›´ã€‚
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim , torch.Size([1, 3, 640, 480])
        t2 = time_sync()
        dt[0] += t2 - t1

        # Inference
        # æ ¹æ®æ˜¯å¦éœ€è¦å¯è§†åŒ–æ¥ç¡®å®šä¸€ä¸ªè·¯å¾„ï¼Œå¹¶å¯èƒ½åˆ›å»ºç›¸å…³çš„ç›®å½•ã€‚
        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False

        # ä½¿ç”¨æ¨¡å‹å¯¹è¾“å…¥çš„å›¾åƒ im è¿›è¡Œæ¨ç†è®¡ç®—ï¼ŒåŒæ—¶è€ƒè™‘æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼ºä»¥åŠæ˜¯å¦è¿›è¡Œå¯è§†åŒ–æ“ä½œï¼Œå¾—åˆ°é¢„æµ‹ç»“æœ pred ã€‚
        pred = model(im, augment=augment, visualize=visualize) # torch.Size([1, 18900, 85])  æ£€æµ‹å‡º18900ä¸ªæ£€æµ‹æ¡†
        t3 = time_sync()
        dt[1] += t3 - t2

        # NMS
        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det) # 1,5,6 . [6.72000e+02, 3.95000e+02, 8.10000e+02, 8.78000e+02, 8.96172e-01, 0.00000e+00]
        dt[2] += time_sync() - t3

        # Second-stage classifier (optional)
        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

        # Process predictions
        for i, det in enumerate(pred):  # per image,torch.Size([5, 6])   detè¡¨ç¤º5ä¸ªæ£€æµ‹æ¡†  ä»¥åŠå¯¹åº”çš„6ä¸ªä¿¡æ¯
            seen += 1  # æ¯å¤„ç†ä¸€å¼ å›¾ç‰‡  æ•°é‡ä¼šåŠ 1
            if webcam:  # batch_size >= 1
                p, im0, frame = path[i], im0s[i].copy(), dataset.count
                s += f'{i}: '
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)   # å¦‚æœæ²¡æœ‰frameå±æ€§  è¿™ä¸ªå€¼å°±æ˜¯0

            p = Path(p)  # to Path
            save_path = str(save_dir / p.name)  # im.jpg, "runs\\detect\\exp3","bus.jpg"
            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt
            s += '%gx%g ' % im.shape[2:]  # print string å›¾ç‰‡çš„é«˜åº¦å’Œå®½åº¦ï¼Œä½œä¸ºæ‰“å°ä¿¡æ¯
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            imc = im0.copy() if save_crop else im0  # for save_crop
            annotator = Annotator(im0, line_width=line_thickness, example=str(names))
            if len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()

                # Print results

                # è·å–æ£€æµ‹ç»“æœä¸­æœ€åä¸€åˆ—ï¼ˆé€šå¸¸æ˜¯ç±»åˆ«æ ‡è¯†ï¼‰çš„ä¸åŒå€¼
                for c in det[:, -1].unique():
                    # è®¡ç®—å±äºè¯¥ç±»åˆ«çš„æ£€æµ‹ç»“æœçš„æ•°é‡ã€‚
                    n = (det[:, -1] == c).sum()  # detections per class
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                # Write results
                # *xyxyè¡¨ç¤ºåæ ‡ï¼Œconfè¡¨ç¤ºç½®ä¿¡åº¦ï¼Œclsè¡¨ç¤ºç±»åˆ«
                for *xyxy, conf, cls in reversed(det):
                    if save_txt:  # Write to file
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        with open(txt_path + '.txt', 'a') as f:
                            f.write(('%g ' * len(line)).rstrip() % line + '\n')

                    if save_img or save_crop or view_img:  # Add bbox to image
                        c = int(cls)  # integer class
                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')
                        annotator.box_label(xyxy, label, color=colors(c, True))
                        if save_crop:
                            save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)

            # Stream results #è¿”å›ç”»å¥½çš„å›¾ç‰‡
            im0 = annotator.result()
            if view_img:
                cv2.imshow(str(p), im0)
                cv2.waitKey(10)  # 10 millisecond

            # Save results (image with detections) ä¿å­˜å›¾åƒ
            if save_img:
                if dataset.mode == 'image':
                    cv2.imwrite(save_path, im0)
                else:  # 'video' or 'stream'
                    if vid_path[i] != save_path:  # new video
                        vid_path[i] = save_path
                        if isinstance(vid_writer[i], cv2.VideoWriter):
                            vid_writer[i].release()  # release previous video writer
                        if vid_cap:  # video
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)
                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        else:  # stream
                            fps, w, h = 30, im0.shape[1], im0.shape[0]
                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos
                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
                    vid_writer[i].write(im0)

        # Print time (inference-only)
        LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')

    # Print results
    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image
    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)
    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    if update:
        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)


def parse_opt():
    parser = argparse.ArgumentParser()  #åˆ›å»ºå‚æ•°è§£æå™¨å¯¹è±¡
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path(s)')
    """
    nargså‚æ•°ç”¨äºæŒ‡å®šåº”è¯¥ä»å‘½ä»¤è¡Œä¸­æ¥å—å¤šå°‘ä¸ªå‚æ•°ã€‚
    å½“nargsçš„å€¼ä¸º'+'æ—¶ï¼Œè¡¨ç¤ºæ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå‚æ•°ï¼Œå¹¶å°†è¿™äº›å‚æ•°ä½œä¸ºåˆ—è¡¨å­˜å‚¨ã€‚
    ä¾‹å¦‚ï¼Œå¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®šäº†--weights a.pt b.pt c.pt,é‚£ä¹ˆargs.weightså°†å­˜å‚¨ä¸º['a.pt', 'b.pt', 'c.pt']ã€‚
    --weightsæ˜¯ä¸€ä¸ªé€‰é¡¹å‚æ•°ï¼Œç”¨äºæŒ‡å®šæ¨¡å‹çš„è·¯å¾„ã€‚nargs='+'è¡¨ç¤ºå¯ä»¥æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹è·¯å¾„ï¼Œ
    ç„¶åå°†è¿™äº›è·¯å¾„ä½œä¸ºä¸€ä¸ªåˆ—è¡¨å­˜å‚¨åœ¨args.weightsä¸­ã€‚
    å¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š--weightså‚æ•°,åˆ™é»˜è®¤å€¼ä¸ºROOT / 'yolov5s.pt';
    helpå‚æ•°æ˜¯ç”¨äºæä¾›å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯,å½“ç”¨æˆ·åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨--helpé€‰é¡¹æ—¶.è¿™äº›å¸®åŠ©ä¿¡æ¯å°†è¢«æ˜¾ç¤ºå‡ºæ¥ï¼Œä»¥ä¾¿ç”¨æˆ·äº†è§£å¦‚ä½•æ­£ç¡®ä½¿ç”¨è¯¥å‚æ•°ã€‚
    åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå¸®åŠ©ä¿¡æ¯æ˜¯ 'model path(s)'ï¼Œç”¨äºæè¿°--weightså‚æ•°è¡¨ç¤ºæ¨¡å‹è·¯å¾„çš„å«ä¹‰ã€‚
    """

    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob, 0 for webcam')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --source çš„é€‰é¡¹å‚æ•°ã€‚å®ƒç”¨äºæŒ‡å®šæ–‡ä»¶ã€ç›®å½•ã€URLæˆ–é€šé…ç¬¦,æˆ–è€…ä½¿ç”¨æ•°å­— 0 è¡¨ç¤ºä½¿ç”¨ç½‘ç»œæ‘„åƒå¤´ä½œä¸ºè¾“å…¥ã€‚

    --source:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --sourceã€‚
    type=str:æŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºå­—ç¬¦ä¸²ã€‚
    default=ROOT / 'data/images'ï¼šå¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š --source å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸º ROOT / 'data/images'ã€‚
    è¿™é‡Œ ROOT / 'data/images' è¡¨ç¤ºæ–‡ä»¶ç³»ç»Ÿä¸­çš„è·¯å¾„ï¼Œå…·ä½“çš„å€¼å–å†³äºç¨‹åºä¸­å®šä¹‰çš„ ROOT å˜é‡ã€‚
    help='file/dir/URL/glob, 0 for webcam'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --source å‚æ•°çš„ç”¨é€”,å³å®ƒå¯ä»¥æ¥å—æ–‡ä»¶ã€ç›®å½•ã€URLã€é€šé…ç¬¦æˆ–æ•°å­— 0 è¡¨ç¤ºä½¿ç”¨ç½‘ç»œæ‘„åƒå¤´ä½œä¸ºè¾“å…¥ã€‚
    
    """
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='(optional) dataset.yaml path')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --data çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæŒ‡å®šæ•°æ®é›†çš„è·¯å¾„ã€‚

    --data:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --dataã€‚
    type=str:æŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºå­—ç¬¦ä¸²ã€‚
    default=ROOT / 'data/coco128.yaml'ï¼šå¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š --data å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸º ROOT / 'data/coco128.yaml'ã€‚
    è¿™é‡Œ ROOT / 'data/coco128.yaml' è¡¨ç¤ºæ–‡ä»¶ç³»ç»Ÿä¸­çš„è·¯å¾„ï¼Œå…·ä½“çš„å€¼å–å†³äºç¨‹åºä¸­å®šä¹‰çš„ ROOT å˜é‡ã€‚
    help='(optional) dataset.yaml path'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --data å‚æ•°çš„ç”¨é€”ï¼Œå³å®ƒç”¨äºæŒ‡å®šæ•°æ®é›†çš„è·¯å¾„ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯é€‰çš„å‚æ•°ã€‚
    
    """

    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --imgsz çš„é€‰é¡¹å‚æ•°ï¼ŒåŒæ—¶è¿˜æ·»åŠ äº† --img å’Œ --img-size ä½œä¸ºè¯¥é€‰é¡¹å‚æ•°çš„åˆ«åã€‚è¯¥é€‰é¡¹å‚æ•°ç”¨äºæŒ‡å®šæ¨æ–­è¿‡ç¨‹ä¸­çš„å›¾åƒå°ºå¯¸ã€‚
    --imgszã€--imgã€--img-size:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --imgsz,åŒæ—¶æ·»åŠ äº† --img å’Œ --img-size ä½œä¸ºè¯¥é€‰é¡¹å‚æ•°çš„åˆ«åã€‚
    è¿™æ„å‘³ç€å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ä»»æ„ä¸€ä¸ªåç§°æ¥æŒ‡å®šè¯¥é€‰é¡¹å‚æ•°ã€‚
    nargs='+'ï¼šæŒ‡å®šè¯¥é€‰é¡¹å‚æ•°å¯ä»¥æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå€¼ï¼Œå¹¶å°†è¿™äº›å€¼ä½œä¸ºåˆ—è¡¨å­˜å‚¨ã€‚
    ä¾‹å¦‚ï¼Œåœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®š --imgsz 640 480 å°†ä¼šå°† [640, 480] å­˜å‚¨åœ¨å‚æ•°çš„å€¼ä¸­ã€‚
    type=int:æŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºæ•´æ•°ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºæ•´æ•°ã€‚
    default=[640]ï¼šå¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®šè¯¥é€‰é¡¹å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸º [640]ï¼Œå³ä¸€ä¸ªåŒ…å«å•ä¸ªæ•´æ•° 640 çš„åˆ—è¡¨ã€‚
    help='inference size h,w'ï¼šæä¾›äº†å…³äºè¯¥é€‰é¡¹å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº†è¯¥é€‰é¡¹å‚æ•°çš„ç”¨é€”ï¼Œå³æŒ‡å®šæ¨æ–­è¿‡ç¨‹ä¸­çš„å›¾åƒå°ºå¯¸ï¼Œå…¶ä¸­ h å’Œ w è¡¨ç¤ºé«˜åº¦å’Œå®½åº¦ã€‚
        
    """

    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --conf-thres çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæŒ‡å®šç½®ä¿¡åº¦é˜ˆå€¼ã€‚

    --conf-thres:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --conf-thresã€‚
    type=float:æŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºæµ®ç‚¹æ•°ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºæµ®ç‚¹æ•°ã€‚
    default=0.25:å¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š --conf-thres å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸º 0.25ã€‚
    help='confidence threshold'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --conf-thres å‚æ•°çš„ç”¨é€”ï¼Œå³æŒ‡å®šç½®ä¿¡åº¦é˜ˆå€¼ã€‚
    """

    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')

    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --max-det çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæŒ‡å®šæ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°ã€‚

    --max-det:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --max-detã€‚
    type=int:æŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºæ•´æ•°ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºæ•´æ•°ã€‚
    default=1000:å¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š --max-det å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸º 1000ã€‚
    help='maximum detections per image'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --max-det å‚æ•°çš„ç”¨é€”ï¼Œå³æŒ‡å®šæ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°ã€‚
    """
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --device çš„é€‰é¡¹å‚æ•°,ç”¨äºæŒ‡å®šä½¿ç”¨çš„è®¡ç®—è®¾å¤‡(GPU æˆ– CPU)ã€‚

    --device:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --deviceã€‚
    default=''ï¼šå¦‚æœåœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰æŒ‡å®š --device å‚æ•°ï¼Œåˆ™é»˜è®¤å€¼ä¸ºç©ºå­—ç¬¦ä¸² ''ã€‚
    help='cuda device, i.e. 0 or 0,1,2,3 or cpu'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --device å‚æ•°çš„ç”¨é€”ï¼Œå³æŒ‡å®šä½¿ç”¨çš„è®¡ç®—è®¾å¤‡ã€‚ç”¨æˆ·å¯ä»¥è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ª GPU è®¾å¤‡çš„ç´¢å¼•ï¼ˆä¾‹å¦‚ 0 æˆ– 0,1,2,3),ä¹Ÿå¯ä»¥è¾“å…¥ cpu è¡¨ç¤ºä½¿ç”¨ CPUã€‚
    """
    parser.add_argument('--view-img', action='store_true', help='show results')  #ä¼šé—ªç°
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --view-img çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦æ˜¾ç¤ºç»“æœã€‚

    --view-img:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --view-imgã€‚
    action='store_true'ï¼šæŒ‡å®šå½“å‘½ä»¤è¡Œä¸­å‡ºç° --view-img å‚æ•°æ—¶ï¼Œå°†è¯¥å‚æ•°è®¾ä¸º Trueã€‚å¦‚æœå‘½ä»¤è¡Œä¸­æ²¡æœ‰å‡ºç°è¯¥å‚æ•°,åˆ™é»˜è®¤ä¸º Falseã€‚
    help='show results'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --view-img å‚æ•°çš„ç”¨é€”ï¼Œå³æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºç»“æœã€‚å½“æŒ‡å®šäº† --view-img å‚æ•°æ—¶ï¼Œç¨‹åºå°†æ˜¾ç¤ºç»“æœï¼›å¦åˆ™ï¼Œç»“æœå°†ä¸ä¼šè¢«æ˜¾ç¤ºã€‚
    """
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')

    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --save-txt çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦å°†ç»“æœä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ã€‚
    --save-txt:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --save-txtã€‚
    action='store_true'ï¼šæŒ‡å®šå½“å‘½ä»¤è¡Œä¸­å‡ºç° --save-txt å‚æ•°æ—¶ï¼Œå°†è¯¥å‚æ•°è®¾ä¸º Trueã€‚å¦‚æœå‘½ä»¤è¡Œä¸­æ²¡æœ‰å‡ºç°è¯¥å‚æ•°,åˆ™é»˜è®¤ä¸º Falseã€‚
    help='save results to *.txt'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --save-txt å‚æ•°çš„ç”¨é€”ï¼Œå³æ§åˆ¶æ˜¯å¦å°†ç»“æœä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ã€‚
    å½“æŒ‡å®šäº† --save-txt å‚æ•°æ—¶ï¼Œç¨‹åºå°†æŠŠç»“æœä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼›å¦åˆ™ï¼Œç»“æœå°†ä¸ä¼šä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ã€‚

    """

    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    """
    ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨ä¿å­˜çš„æ–‡æœ¬æ ‡ç­¾ä¸­åŒ…å«ç½®ä¿¡åº¦ä¿¡æ¯ã€‚
    --save-conf:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --save-confã€‚
    action='store_true'ï¼šæŒ‡å®šå½“å‘½ä»¤è¡Œä¸­å‡ºç° --save-conf å‚æ•°æ—¶ï¼Œå°†è¯¥å‚æ•°è®¾ä¸º Trueã€‚å¦‚æœå‘½ä»¤è¡Œä¸­æ²¡æœ‰å‡ºç°è¯¥å‚æ•°,åˆ™é»˜è®¤ä¸º Falseã€‚
    help='save confidences in --save-txt labels'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --save-conf å‚æ•°çš„ç”¨é€”ï¼Œå³æ§åˆ¶æ˜¯å¦åœ¨ä¿å­˜çš„æ–‡æœ¬æ ‡ç­¾ä¸­åŒ…å«ç½®ä¿¡åº¦ä¿¡æ¯ã€‚
    å½“æŒ‡å®šäº† --save-conf å‚æ•°æ—¶ï¼Œç¨‹åºå°†åœ¨ä¿å­˜çš„æ–‡æœ¬æ ‡ç­¾ä¸­åŒ…å«ç½®ä¿¡åº¦ä¿¡æ¯ï¼›å¦åˆ™ï¼Œæ–‡æœ¬æ ‡ç­¾ä¸­å°†ä¸åŒ…å«ç½®ä¿¡åº¦ä¿¡æ¯ã€‚

    """
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --save-crop çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦ä¿å­˜è£å‰ªåçš„é¢„æµ‹æ¡†ã€‚
    --save-crop:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --save-cropã€‚
    action='store_true'ï¼šæŒ‡å®šå½“å‘½ä»¤è¡Œä¸­å‡ºç° --save-crop å‚æ•°æ—¶ï¼Œå°†è¯¥å‚æ•°è®¾ä¸º Trueã€‚
    å¦‚æœå‘½ä»¤è¡Œä¸­æ²¡æœ‰å‡ºç°è¯¥å‚æ•°ï¼Œåˆ™é»˜è®¤ä¸º Falseã€‚
    help='save cropped prediction boxes'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --save-crop å‚æ•°çš„ç”¨é€”ï¼Œå³æ§åˆ¶æ˜¯å¦ä¿å­˜è£å‰ªåçš„é¢„æµ‹æ¡†ã€‚
    å½“æŒ‡å®šäº† --save-crop å‚æ•°æ—¶ï¼Œç¨‹åºå°†ä¿å­˜è£å‰ªåçš„é¢„æµ‹æ¡†ï¼›å¦åˆ™ï¼Œä¸ä¿å­˜è£å‰ªåçš„é¢„æµ‹æ¡†ã€‚
    """
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    """
    è¯¥ä»£ç æ·»åŠ äº†ä¸€ä¸ªåä¸º --classes çš„é€‰é¡¹å‚æ•°ï¼Œç”¨äºæŒ‰ç±»åˆ«è¿›è¡Œè¿‡æ»¤ã€‚
    --classesï¼šæŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --classesã€‚
    nargs='+'ï¼šæŒ‡å®šè¯¥é€‰é¡¹å‚æ•°å¯ä»¥æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå€¼ï¼Œå¹¶å°†è¿™äº›å€¼ä½œä¸ºåˆ—è¡¨å­˜å‚¨ã€‚ä¾‹å¦‚ï¼Œåœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®š --classes 0 2 3 å°†ä¼šå°† [0, 2, 3] å­˜å‚¨åœ¨å‚æ•°çš„å€¼ä¸­ã€‚
    type=intï¼šæŒ‡å®šäº†å‚æ•°çš„ç±»å‹ä¸ºæ•´æ•°ï¼Œå³è¾“å…¥çš„å€¼å°†è¢«è§£æä¸ºæ•´æ•°ã€‚
    help='filter by class: --classes 0, or --classes 0 2 3'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --classes å‚æ•°çš„ç”¨é€”ï¼Œå³æŒ‰ç…§æŒ‡å®šçš„ç±»åˆ«è¿›è¡Œè¿‡æ»¤ã€‚
    ç”¨æˆ·å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ä¸€ä¸ªæˆ–å¤šä¸ªæ•´æ•°å€¼æ¥æŒ‡å®šè¿‡æ»¤çš„ç±»åˆ«ã€‚
    ä¾‹å¦‚ï¼Œ--classes 0 è¡¨ç¤ºåªä¿ç•™ç±»åˆ«ä¸º 0 çš„ç»“æœï¼Œ--classes 0 2 3 è¡¨ç¤ºåªä¿ç•™ç±»åˆ«ä¸º 0ã€2 å’Œ 3 çš„ç»“æœã€‚
    """

    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')

    """
    ç”¨äºæ‰§è¡Œç±»åˆ«ä¸å¯çŸ¥çš„éæå¤§å€¼æŠ‘åˆ¶(class-agnostic NMS)ã€‚
    --agnostic-nms:æŒ‡å®šäº†å‚æ•°çš„åç§°ä¸º --agnostic-nmsã€‚
    action='store_true'ï¼šæŒ‡å®šå½“å‘½ä»¤è¡Œä¸­å‡ºç° --agnostic-nms å‚æ•°æ—¶ï¼Œå°†è¯¥å‚æ•°è®¾ä¸º Trueã€‚å¦‚æœå‘½ä»¤è¡Œä¸­æ²¡æœ‰å‡ºç°è¯¥å‚æ•°ï¼Œåˆ™é»˜è®¤ä¸º Falseã€‚
    help='class-agnostic NMS'ï¼šæä¾›äº†å…³äºè¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ï¼Œå½“ç”¨æˆ·ä½¿ç”¨ --help é€‰é¡¹æ—¶ä¼šæ˜¾ç¤ºã€‚
    å¸®åŠ©ä¿¡æ¯æè¿°äº† --agnostic-nms å‚æ•°çš„ç”¨é€”ï¼Œå³æ‰§è¡Œç±»åˆ«ä¸å¯çŸ¥çš„éæå¤§å€¼æŠ‘åˆ¶ã€‚
    å½“æŒ‡å®šäº† --agnostic-nms å‚æ•°æ—¶ï¼Œç¨‹åºå°†åœ¨æ‰§è¡Œéæå¤§å€¼æŠ‘åˆ¶æ—¶ä¸è€ƒè™‘ç‰©ä½“çš„ç±»åˆ«ä¿¡æ¯ï¼›å¦åˆ™ï¼Œä¼šè€ƒè™‘ç‰©ä½“çš„ç±»åˆ«ä¿¡æ¯è¿›è¡ŒæŠ‘åˆ¶ã€‚
    """
    parser.add_argument('--augment', action='store_true', help='augmented inference')

    # å³æ‰§è¡Œå¢å¼ºæ¨ç†ã€‚å½“æŒ‡å®šäº† --augment å‚æ•°æ—¶ï¼Œç¨‹åºå°†ä½¿ç”¨å¢å¼ºæŠ€æœ¯ï¼ˆå¦‚éšæœºè£å‰ªã€ç¼©æ”¾ã€ç¿»è½¬ç­‰ï¼‰å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå¢å¼ºï¼Œä»¥æå‡æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚
 
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    # å³å¯è§†åŒ–ç‰¹å¾ã€‚å½“æŒ‡å®šäº† --visualize å‚æ•°æ—¶ï¼Œç¨‹åºå°†å¯è§†åŒ–æ¨¡å‹çš„ç‰¹å¾ï¼Œä»¥å¸®åŠ©ç†è§£æ¨¡å‹çš„å·¥ä½œæ–¹å¼ã€è§‚å¯Ÿç‰¹å¾çš„å˜åŒ–ç­‰ã€‚

    parser.add_argument('--update', action='store_true', help='update all models')
    # æ›´æ–°æ‰€æœ‰æ¨¡å‹ã€‚å½“æŒ‡å®šäº† --update å‚æ•°æ—¶ï¼Œç¨‹åºå°†æ‰§è¡Œæ›´æ–°æ“ä½œï¼Œå¯èƒ½åŒ…æ‹¬ä¸‹è½½æœ€æ–°çš„æ¨¡å‹æƒé‡æ–‡ä»¶ã€æ›´æ–°é…ç½®æ–‡ä»¶ç­‰ã€‚


    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')
    # å³æŒ‡å®šç»“æœä¿å­˜çš„é¡¹ç›®è·¯å¾„ã€‚ç”¨æˆ·å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ --project å‚æ•°æ¥æŒ‡å®šç»“æœä¿å­˜çš„é¡¹ç›®è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚ç»“æœå°†ä¿å­˜åœ¨æŒ‡å®šçš„é¡¹ç›®è·¯å¾„ä¸‹ã€‚

    parser.add_argument('--name', default='exp', help='save results to project/name')
    # æŒ‡å®šç»“æœä¿å­˜çš„åç§°ã€‚ç”¨æˆ·å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ --name å‚æ•°æ¥æŒ‡å®šç»“æœä¿å­˜çš„åç§°ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚ç»“æœå°†ä¿å­˜åœ¨é¡¹ç›®è·¯å¾„ä¸‹ï¼Œå¹¶ä»¥æŒ‡å®šçš„åç§°å‘½åã€‚


    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment') #æ²¡å•¥ç”¨
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    # ç”¨æˆ·å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ --line-thickness å‚æ•°æ¥æŒ‡å®šè¾¹ç•Œæ¡†çº¿æ¡çš„ç²—ç»†ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼ã€‚è¾¹ç•Œæ¡†çº¿æ¡çš„ç²—ç»†ä»¥åƒç´ ä¸ºå•ä½ã€‚

    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    opt = parser.parse_args()
    # è¿™è¡Œä»£ç å°†è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨å˜é‡ opt ä¸­ã€‚opt æ˜¯ä¸€ä¸ªåŒ…å«è§£æåçš„å‚æ•°å€¼çš„å¯¹è±¡ã€‚
    
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    print_args(vars(opt)) # è¿™è¡Œä»£ç å°†ä½¿ç”¨ vars() å‡½æ•°è·å– opt å¯¹è±¡çš„å±æ€§å’Œå€¼ï¼Œ
    return opt


def main(opt):
    check_requirements(exclude=('tensorboard', 'thop')) # excludeå‚æ•°å¯ä»¥ä½¿ç”¨ä»»ä½•å­—ç¬¦ä¸²å€¼ä½œä¸ºå‚æ•°å€¼ï¼Œç”¨äºæŒ‡å®šè¦æ’é™¤çš„ä¾èµ–é¡¹æˆ–æ¨¡å—ã€‚
    run(**vars(opt))


if __name__ == "__main__":
    opt = parse_opt()
    main(opt)
